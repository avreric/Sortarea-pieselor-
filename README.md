# ğŸ“˜ README â€“ Etapa 3: Analiza È™i PregÄƒtirea Setului de Date pentru ReÈ›ele Neuronale

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** [Avram Eric Mario]  
**Proiect:** Sortarea Pieselor  
**Data:** [20.11.2025]

---

## Introducere

Acest document descrie activitÄƒÈ›ile realizate Ã®n **Etapa 3**, avÃ¢nd ca scop pregÄƒtirea setului de date pentru proiectul **â€Detectarea Defectelor Ã®n Piese Mecanice"**. Obiectivul final este antrenarea unui model de tip **Vision Transformer (ViT)** capabil sÄƒ clasifice automat imaginile industriale Ã®n douÄƒ categorii: *Piese Bune* È™i *Piese Defecte*[cite: 11, 32].

Procesul respectÄƒ fluxul standard de Machine Learning: achiziÈ›ie, analizÄƒ exploratorie (EDA), curÄƒÈ›are È™i preprocesare (inclusiv augmentare pentru a compensa necesitatea unui set mare de date ).

---

## 1. Structura Repository-ului Github (versiunea Etapei 3)

Structura a fost adaptatÄƒ pentru un proiect de Computer Vision implementat Ã®n Python/PyTorch:
```
  Defect-Detection-ViT/
â”œâ”€â”€ README.md              # DocumentaÈ›ia curentÄƒ
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ dataset/info.md    # Detalii despre sursa imaginilor È™i etichete
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Imaginile originale organizate (ex: folder 'defective', folder 'ok')
â”‚   â”œâ”€â”€ processed/         # Imaginile redimensionate È™i normalizate (numpy arrays / tensors)
â”‚   â”œâ”€â”€ train/             # Sub-setul de antrenare
â”‚   â”œâ”€â”€ validation/        # Sub-setul de validare
â”‚   â””â”€â”€ test/              # Sub-setul de testare
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py   # Scripturi pentru resize, normalizare, augmentare (OpenCV/Albumentations)
â”‚   â”œâ”€â”€ analysis.py        # Scripturi pentru generarea histogramelor È™i EDA
â”‚   â””â”€â”€ utils.py           # FuncÈ›ii auxiliare
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml        # Parametri (img_size: 224, batch_size: 32, etc.)
â””â”€â”€ requirements.txt       # DependenÈ›e: PyTorch, OpenCV, Matplotlib, NumPy [cite: 52]

##2. Descrierea Setului de Date

###2.1 Sursa datelor

    Origine: Dataset public reprezentativ pentru piese turnate (ex: Casting Product Image Data for Quality Inspection), simulant o linie de producÈ›ie realÄƒ.

Modul de achiziÈ›ie: Imagini capturate prin camere video industriale (vedere de sus), iluminare controlatÄƒ.

    Perioada / condiÈ›iile colectÄƒrii: Imagini statice, format grayscale sau RGB, focalizate pe piesa de interes.

###2.2 Caracteristicile dataset-ului

    NumÄƒr total de observaÈ›ii: [Ex: 7,348 imagini] (CompleteazÄƒ cu numÄƒrul real din dataset-ul ales).

    NumÄƒr de clase: 2 (Clasificare binarÄƒ: ok_front vs def_front).

Tipuri de date: Imagini (Matrici de pixeli).

Format fiÈ™iere: â˜ CSV / â˜ TXT / â˜ JSON / â˜‘ PNG/JPG / â˜ Altele.

###2.3 Descrierea caracteristicilor (Atributele Imaginilor)

Deoarece lucrÄƒm cu date nestructurate (imagini), caracteristicile sunt definite de proprietÄƒÈ›ile vizuale È™i metadate:

| **CaracteristicÄƒ** | **Tip** | **Unitate** | **Descriere** | **Domeniu valori** |
|--------------------|---------|-------------|---------------|--------------------|
| Image_Height | numeric | pixeli | ÃnÄƒlÈ›imea imaginii originale | [ex: 300] |
| Image_Width | numeric | pixeli | LÄƒÈ›imea imaginii originale | [ex: 300] |
| Channels | numeric | - | Canale de culoare (1=Gray, 3=RGB) | {1, 3} |
| Pixel_Intensity | numeric | - | Valoarea intensitÄƒÈ›ii unui pixel | 0 â€“ 255 |
| **Label** (Target) | categorial | - | Clasificarea piesei (defectÄƒ/bunÄƒ) | {0 (Bun), 1 (Defect)} |


##3. Analiza Exploratorie a Datelor (EDA) â€“ Sintetic

###3.1 Statistici descriptive aplicate

    DistribuÈ›ia claselor: S-a calculat numÄƒrul de imagini pentru fiecare clasÄƒ pentru a verifica echilibrul setului de date.

    Analiza dimensiunilor: Verificarea consistenÈ›ei rezoluÈ›iei imaginilor (toate au aceeaÈ™i dimensiune sau necesitÄƒ resize?).

    DistribuÈ›ia intensitÄƒÈ›ii pixelilor: Histograme ale valorilor medii ale pixelilor pentru a detecta imagini prea Ã®ntunecate sau supraexpuse.

###3.2 Analiza calitÄƒÈ›ii datelor

    Detectarea imaginilor corupte: Verificarea fiÈ™ierelor care nu pot fi deschise cu biblioteca OpenCV.

Verificarea duplicatelor: Identificarea imaginilor identice care ar putea duce la data leakage Ã®ntre Train È™i Test.

Analiza vizualÄƒ: Vizualizarea randomizatÄƒ a mostrelor pentru a confirma etichetarea corectÄƒ (ex: fisuri vizibile pe piesele etichetate ca "Defect").

###3.3 Probleme identificate

    Dezechilibru de clasÄƒ (Class Imbalance): S-a observat cÄƒ numÄƒrul pieselor "Bune" este mai mare decÃ¢t al celor "Defecte" (situaÈ›ie tipicÄƒ Ã®n industrie).

        Impact: Modelul ar putea tinde sÄƒ prezicÄƒ mereu "PiesÄƒ BunÄƒ".

    VariaÈ›ii de poziÈ›ie: Piesele nu sunt centrate perfect Ã®n toate imaginile.

    Dimensiune limitatÄƒ a setului de date: NumÄƒrul de imagini cu defecte specifice este mic, ceea ce necesitÄƒ tehnici de augmentare.


##4. Preprocesarea Datelor

###4.1 CurÄƒÈ›area datelor

    Eliminare fiÈ™iere corupte: S-au È™ters imaginile care aveau dimensiunea 0kb sau format invalid.

    Filtrare: S-au pÄƒstrat doar imaginile care conÈ›in piesa completÄƒ Ã®n cadru.

###4.2 Transformarea caracteristicilor

Pentru a pregÄƒti imaginile pentru Vision Transformer (ViT), s-au aplicat urmÄƒtoarele transformÄƒri folosind torchvision.transforms:

    Redimensionare (Resize): Toate imaginile au fost aduse la dimensiunea standard de 224x224 pixeli (cerinÈ›Äƒ standard ViT).

    Normalizare: Valorile pixelilor (0-255) au fost scalate Ã®n intervalul [0, 1] È™i apoi normalizate folosind media È™i deviaÈ›ia standard (ex: ImageNet stats: mean=[0.485, ...], std=[0.229, ...]).

    Augmentarea Datelor (Data Augmentation): Pentru a combate limitÄƒrile setului de date, s-au aplicat pe setul de antrenare:

        Random Horizontal Flip

        Random Rotation (Â±10 grade)

        AjustÄƒri uÈ™oare de luminozitate.

###4.3 Structurarea seturilor de date

Setul de date a fost Ã®mpÄƒrÈ›it aleatoriu, dar stratificat (pÄƒstrÃ¢nd proporÈ›ia defect/bun), Ã®n:

    70% â€“ Train: Pentru antrenarea parametrilor modelului ViT.

    15% â€“ Validation: Pentru monitorizarea performanÈ›ei È™i ajustarea hiperparametrilor.

    15% â€“ Test: Pentru evaluarea finalÄƒ obiectivÄƒ.

###4.4 Salvarea rezultatelor preprocesÄƒrii

    Imaginile brute au rÄƒmas Ã®n data/raw/ pentru siguranÈ›Äƒ.

    Scripturile de Dataloaders din PyTorch au fost configurate pentru a citi È™i transforma datele Ã®n timp real (on-the-fly) pentru a economisi spaÈ›iu pe disc.

##5. FiÈ™iere Generate Ã®n AceastÄƒ EtapÄƒ

    data/raw/ â€“ Folderul cu dataset-ul original descÄƒrcat.

    src/preprocessing/data_loader.py â€“ Codul Python pentru Ã®ncÄƒrcarea È™i augmentarea imaginilor.

    src/analysis/eda_notebook.ipynb â€“ Notebook Jupyter cu graficele distribuÈ›iilor È™i exemple de imagini.

    data/split/ â€“ FiÈ™iere text sau CSV care conÈ›in listele de fiÈ™iere pentru train/val/test (pentru reproductibilitate).

##6. Stare EtapÄƒ

    [x] StructurÄƒ repository configuratÄƒ conform cerinÈ›elor.

    [x] Dataset achiziÈ›ionat È™i analizat (EDA realizatÄƒ - vezi grafice).

    [x] Pipeline de preprocesare (Resize, Normalize) implementat Ã®n PyTorch.

    [x] Strategia de augmentare definitÄƒ pentru a rezolva lipsa datelor.

    [x] DocumentaÈ›ie actualizatÄƒ.





